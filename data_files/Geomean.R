library(adehabitatMA)
library(adehabitatHR)
library(raster)
library(SDMTools)
split_test_train <- dget("split_test_train.R")
spat_interpolate <- dget("spat_interpolate.R")

#Read in occurrence data
#ZP3

#READ IN SPATIAL DATAFRAME WITH X AND Y VALUES AS LAT/LONG COORDINATES
#spa

#How many repetitions of the test/train split?
rep <- 100

#Create a dataframe to hold the spatial interpolation results for each species, calculated with either (I) an 80% training : 20% testing split (if the species appears at > 25 sites), (II) a 60:40 split (if the species appears at >= 13 sites), or (III) no split at all (if the species appears at < 13 sites.
dat <- array(NA, dim=c(dim(ZP3)[2],dim(ZP3)[1],3), dimnames=list(colnames(ZP3),rownames(ZP3),c("80.20","60.40","0")))

record <- array(NA, dim=c(dim(ZP3)[2],dim(ZP3)[1],100,3), dimnames=list(colnames(ZP3),rownames(ZP3),NULL,c("80.20","60.40","0")))

##For the 80:20 split...
#For each species, create a species + spatial object
for(i in 1:dim(ZP3)[2]){  #for each species...
  for(z in 1:rep){
    #Create species + spatial object
    object <- cbind(ZP3[,i],spa$LONG,spa$LAT)
    colnames(object) <- c("spec","x","y")
    
    samp <- split_test_train(object,.8)
    
    if(samp[[4]] < 101){
      train <- samp[[2]]
      test2 <- samp[[3]]
      samp <- samp[[1]]
      
      record[i,-samp,z,1] <- spat_interpolate(object, train, test2)
    }
  }
}

for(i in 1:dim(ZP3)[2]){
  blah <- record[i,,,1]
  dat[i,,1] <- rowMeans(blah,na.rm=T)
}

##For the 60:40 split...
#For each species, create a species + spatial object
for(i in 1:dim(ZP3)[2]){  #for each species...
  for(z in 1:rep){
    #Create species + spatial object
    object <- cbind(ZP3[,i],spa$LONG,spa$LAT)
    colnames(object) <- c("spec","x","y")
    
    samp <- split_test_train(object,.6)
    
    if(samp[[4]] < 101){
      train <- samp[[2]]
      test2 <- samp[[3]]
      samp <- samp[[1]]
      
      record[i,-samp,z,2] <- spat_interpolate(object, train, test2)
    }
  }
}

for(i in 1:dim(ZP3)[2]){
  blah <- record[i,,,2]
  dat[i,,2] <- rowMeans(blah,na.rm=T)
}

##For no split...
#For each species, create a species + spatial object
for(i in 1:dim(ZP3)[2]){  #for each species...
  for(y in 1:rep){
    #Create species + spatial object
    object <- cbind(ZP3[,i],spa$LONG,spa$LAT)
    colnames(object) <- c("spec","x","y")
    
    #Take spatial minima and maxima
    xmin <- min(object[,2])
    xmax <- max(object[,2])
    ymin <- min(object[,3])
    ymax <- max(object[,3])
    
    #Global data
    glob1r<-data.frame(cbind((object[,2]-xmin)/abs(xmax-xmin),(object[,3]-ymin)/abs(ymax-ymin)))
    #Species data
    spr<-data.frame(cbind((object[object[,1]==1,2]-xmin)/abs(xmax-xmin),(object[object[,1]==1,3]-ymin)/abs(ymax-ymin)))
    #Spatial grid
    R <- 100
    xy <- cbind((1:R)/R,(1:R)/R)
    xy <- SpatialPoints(xy)
    mask<-ascgen(xy,nrcol=R,count=F)
    spr_xy <- SpatialPoints(spr)
    #Estimation of Utilization Distribution
    KernelEStimation=kernelUD(spr_xy,  kern = c("bivnorm"),grid=mask)
    #image(KernelEStimation, axes = FALSE)
    #Convert to raster
    sp.dens <- raster(as(KernelEStimation,"SpatialPixelsDataFrame"))
    
    #Repeat for global data
    glob1r_xy <- SpatialPoints(glob1r)
    KernelEStimationGlobal<-kernelUD(glob1r_xy,grid=mask,kern="bivnorm")
    global.dens <- raster(as(KernelEStimationGlobal,"SpatialPixelsDataFrame"))
    
    ##Extrating testing
    # All xy points in data
    spr_test<-data.frame(cbind((object[,2]-xmin)/abs(xmax-xmin),(object[,3]-ymin)/abs(ymax-ymin)))
    Sp_predictions=extract(sp.dens, spr_test)#extract points from raster, points are density of a species
    Global_predictions=extract(global.dens, spr_test)#extract points from raster, points are density of the sampling points
    
    z <- Sp_predictions*(nrow(object[object[,1]==1,]))/ (sum(Sp_predictions, na.rm=T)) #rescale density to the number of occurrences in sp
    Z <- Global_predictions*(nrow(object))/ sum(Global_predictions, na.rm=T) #rescale density to the number of sites in glob1 (scale according to the training data only as it is the base for the model building)
    
    # remove infinitesimally small number generated by kernel density function
    z[z<max(z)/1000]<-0
    # remove infinitesimally small number generated by kernel density function
    Z[Z<max(Z)/1000]<-0
    # correct for environment prevalence
    z <- z/Z
    # remove n/0 situations
    z[is.na(z)] <- 0
    # remove n/0 situations
    z[z=="Inf"] <- 0
    # rescale between [0:1] for comparison with other species
    z.cor<-z/max(z)
    
    #tallying up predictions for all species
    TestPredictions=as.data.frame(z.cor)
    TestPredictions=cbind(object[,1], TestPredictions)
    colnames(TestPredictions)=c("X","L")
    
    record[i,,y,3] <- TestPredictions$L
  }
}

for(i in 1:dim(ZP3)[2]){
  blah <- record[i,,,3]
  dat[i,,3] <- rowMeans(blah,na.rm=T)
}

# Arrange spatial occurence predictions for pairs of species (to produce Geomean)
dat2 <- apply(dat,3,rowMeans)

Pairs80.20<-matrix(nrow=16,ncol=16)
Pairs40.60<-matrix(nrow=16,ncol=16)
Pairs<-matrix(nrow=16,ncol=16)
for(i in 1:dim(ZP3)[2]){
  for(j in 1:dim(ZP3)[2]){
    if(dat2[i,1]!="NaN" & dat2[j,1]!="NaN" ){
      Pairs80.20[i,j]<-mean(dat2[c(i,j),1])
    } else {
      Pairs80.20[i,j]<-NA
    }
    if(dat2[i,2]!="NaN"  & dat2[j,2]!="NaN" ){
      Pairs40.60[i,j]<-mean(dat2[c(i,j),2])
    } else {
      Pairs40.60[i,j]<-NA
    }
    if(dat2[i,3]!="NaN"  & dat2[j,3]!="NaN" ){
      Pairs[i,j]<-mean(dat2[c(i,j),3])
    } else {
      Pairs[i,j]<-NA
    }
    j=j+1
  }
  i=i+1
}

length(which(Pairs80.20[upper.tri(Pairs80.20)]!="NA"))
length(which(Pairs40.60[upper.tri(Pairs40.60)]!="NA"))
length(which(Pairs[upper.tri(Pairs)]!="NA"))
Pairs80.20[Pairs80.20[upper.tri(Pairs80.20)]!="NA"]
Pairs40.60[Pairs40.60[upper.tri(Pairs40.60)]!="NA"]
Pairs[Pairs[upper.tri(Pairs)]!="NA"]

dat2 <- as.data.frame(dat2)
dat2$N <- colSums(ZP3)
write.csv(dat2,"spat_interpol.csv")

#MIXED SPLIT AND UNSPLIT DECISION DEPENDING ON NUMBER OF SITES
#**************************************************************
#dat2 <- read.csv("spat_interpol.csv",header=T,row.names=1)
spat <- array(NA,dim=c(ncol(ZP3),2))
rownames(spat) <- rownames(dat2)
colnames(spat) <- c("spat","N")
spat <- as.data.frame(spat)

for(i in 1:nrow(spat)){
  if(dat2$N[i] > 25){
    spat[i,1] <- dat2$`80.20`[i]
    spat[i,2] <- dat2$N[i]
  }
  else if(dat2$N[i] < 13){
    spat[i,1] <- dat2$`0`[i]
    spat[i,2] <- dat2$N[i]
  }
  else{
    spat[i,1] <- dat2$`60.40`[i]
    spat[i,2] <- dat2$N[i]
  }
}

# Create mean interpolated value for all pairs of species
geo_mean<-matrix(nrow=16,ncol=16)
for (i in 1:16){
  for (j in 1:16){
    geo_mean[i,j]<-mean(spat[c(i,j),1])
  }
}
colnames(geo_mean)=rownames(spat)
rownames(geo_mean)=rownames(spat)

# Vector of length 120 with Geomean for all pairs of species with 5 or more occurrences
Geomean_names <- array(NA,dim=c(ncol(sp.combn),2),dimnames=list(NULL,c("sp1","sp2")))
Geomean <- array(NA, dim=ncol(sp.combn))
for(i in 1:(ncol(sp.combn))){
  Geomean_names[i,1] <- sp.list[sp.combn[1,i]]
  Geomean_names[i,2] <- sp.list[sp.combn[2,i]]
  Geomean[i] <- geo_mean[which(rownames(geo_mean) == sp.list[sp.combn[1,i]]) , which(rownames(geo_mean) == sp.list[sp.combn[2,i]])]
}